{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LM_testing",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4plQGMAwOl6q",
        "colab_type": "code",
        "outputId": "ca74944a-fb50-4775-a9b4-e9dbb0dc3d24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!pip install transformers -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▋                               | 10kB 19.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 501kB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 870kB 52.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 30.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.7MB 47.0MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLttX5vjaTO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import transformers as ppb\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1WQq2u4gmqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = ppb.BertTokenizer.from_pretrained('dkleczek/bert-base-polish-uncased-v1')  # re-load\n",
        "bert_model = ppb.BertForMaskedLM.from_pretrained('dkleczek/bert-base-polish-uncased-v1') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW_56IL1gmjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "string1 = 'Adam mickiewicz wielkim polskim [MASK] był .'\n",
        "# string1 = 'Chcę kupić ten samochód bo jest [MASK] . Dawno nie widziałem takiego fajnego auta .'\n",
        "# string1 = 'Polacy nie gęsi lecz swój [MASK] mają'\n",
        "indices = tokenizer.encode(string1, add_special_tokens=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IblYGl8lB1o",
        "colab_type": "code",
        "outputId": "ab3f6f17-45c6-43f7-c12b-320081b9a671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(indices)\n",
        "print(tokenizer.decode(indices))\n",
        "masked_token = np.argwhere(np.array(indices) == 3).flatten()[0]\n",
        "print (masked_token)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 6248, 29914, 8549, 7319, 10318, 3, 2150, 18, 4]\n",
            "[CLS] adam mickiewicz wielkim polskim [MASK] był. [SEP]\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi8eWDPik_-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode text\n",
        "input_ids = torch.tensor([indices])  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = bert_model(input_ids)[0]  # Models outputs are now tuples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smUB5w8Rl26W",
        "colab_type": "code",
        "outputId": "3f9a54ff-9166-45d8-91e7-c9c21a0bedac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(last_hidden_states.shape)\n",
        "print(input_ids.shape)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10, 60000])\n",
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-MiSzQCk_77",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7f8c0212-c4f3-42ec-ee55-234e52e45a61"
      },
      "source": [
        "# DISPLAY MISSING WORDS\n",
        "predicted_words = np.argmax(np.asarray(last_hidden_states[0,masked_token,:]))\n",
        "print(predicted_words)\n",
        "print(tokenizer.decode([predicted_words]))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26596\n",
            "poeta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqblkjyhOyu_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "dc175876-5d17-4178-dc5d-351782ef4fee"
      },
      "source": [
        "more_words = np.argsort(np.asarray(last_hidden_states[0,masked_token,:]))[-4:]\n",
        "print(more_words)\n",
        "for idx in reversed(more_words):\n",
        "  print(tokenizer.decode([idx]))"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[24293  5182 10953 26596]\n",
            "poeta\n",
            "bohaterem\n",
            "człowiekiem\n",
            "pisarzem\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5Htx20EM9iN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}